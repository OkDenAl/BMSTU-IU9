{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx1PAscVjI3C"
      },
      "source": [
        "# Окутин Денис ИУ9-11М Задание 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vN1chCuyiXkw"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzfjhHtujGTI"
      },
      "source": [
        "## Скачивание датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lZBhp9tzjEqC"
      },
      "outputs": [],
      "source": [
        "categories = [\n",
        "    'comp.graphics',\n",
        "    'sci.med',\n",
        "    'alt.atheism',\n",
        "]\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "X_train_raw, y_train = newsgroups_train.data, newsgroups_train.target\n",
        "X_test_raw, y_test = newsgroups_test.data, newsgroups_test.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B1KR8CYjMBR"
      },
      "source": [
        "## Обработка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLVa_IvljOk0",
        "outputId": "8e92637b-ef4c-49f8-a2b7-70c4fd612c25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 29401\n"
          ]
        }
      ],
      "source": [
        "def preprocessing (text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "word_set = set()\n",
        "for text in X_train_raw:\n",
        "    tokens = preprocessing(text)\n",
        "    word_set.update(tokens)\n",
        "\n",
        "vocab = list(word_set)\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZhm1nP_j3FQ"
      },
      "source": [
        "## Кодирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bTatSUiUj6U0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot(text,vocab):\n",
        "    res = np.zeros(len(vocab))\n",
        "    for word in text:\n",
        "        if word in vocab:\n",
        "            index = vocab.index(word)\n",
        "            res[index]=1\n",
        "    return res\n",
        "\n",
        "X_train = []\n",
        "for text in X_train_raw:\n",
        "    tokens = preprocessing(text)\n",
        "    X_train.append(one_hot(tokens,vocab))\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "X_test = []\n",
        "for text in X_test_raw:\n",
        "    tokens = preprocessing(text)\n",
        "    X_test.append(one_hot(tokens,vocab))\n",
        "X_test = np.array(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rK-GJU2kF6t"
      },
      "source": [
        "## Метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M0JWej0_j9_L"
      },
      "outputs": [],
      "source": [
        "def my_accuracy_score(y_true, y_pred):\n",
        "    correct = np.sum(y_true == y_pred)\n",
        "    return correct / len(y_true)\n",
        "\n",
        "def my_precision_score(y_true, y_pred,average='macro'):\n",
        "    classes = np.unique(y_true)\n",
        "    precisions = []\n",
        "\n",
        "    for c in classes:\n",
        "        tp = np.sum((y_pred == c) & (y_true == c))\n",
        "        fp = np.sum((y_pred == c) & (y_true != c))\n",
        "\n",
        "        precision = 0\n",
        "        if (tp + fp) > 0:\n",
        "            precision = tp / (tp + fp)\n",
        "\n",
        "        precisions.append(precision)\n",
        "    if average == 'macro':\n",
        "      return np.mean(precisions)\n",
        "    return precisions\n",
        "\n",
        "def my_recall_score(y_true, y_pred,average='macro'):\n",
        "    classes = np.unique(y_true)\n",
        "    recalls = []\n",
        "\n",
        "    for c in classes:\n",
        "        tp = np.sum((y_pred == c) & (y_true == c))\n",
        "        fn = np.sum((y_true == c) & (y_pred != c))\n",
        "\n",
        "        recall = 0\n",
        "        if (tp + fn) > 0:\n",
        "            recall = tp / (tp + fn)\n",
        "\n",
        "        recalls.append(recall)\n",
        "\n",
        "    if average == 'macro':\n",
        "      return np.mean(recalls)\n",
        "    return recalls\n",
        "\n",
        "def my_f1_score(y_true, y_pred, average='macro'):\n",
        "    precisions = my_precision_score(y_true, y_pred,average=None)\n",
        "    recalls = my_recall_score(y_true, y_pred,average=None)\n",
        "\n",
        "    f1_scores = []\n",
        "    for p, r in zip(precisions, recalls):\n",
        "      f1 = 0\n",
        "      if (p + r) != 0:\n",
        "          f1 = 2 * p * r / (p + r)\n",
        "      f1_scores.append(f1)\n",
        "\n",
        "    if average == 'macro':\n",
        "      return np.mean(f1_scores)\n",
        "\n",
        "    return f1_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBtRxXVspqkt"
      },
      "source": [
        "# Тестирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSMT-0iTjSmi",
        "outputId": "ad81ee1e-87e9-4c48-9f3a-6629ff052f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Подбор параметров для SVM...\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Лучшие параметры SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Лучшая точность SVM (кросс-валидация): 0.9445132391610102\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "svm_param_grid = {\n",
        "    'C': [0.1],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "svm_model = SVC(random_state=42)\n",
        "\n",
        "svm_grid = GridSearchCV(\n",
        "    svm_model,\n",
        "    svm_param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Подбор параметров для SVM...\")\n",
        "svm_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры SVM:\", svm_grid.best_params_)\n",
        "print(\"Лучшая точность SVM (кросс-валидация):\", svm_grid.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fK6Mx8cjjsM",
        "outputId": "0ebfc002-bbac-46ef-d0b8-b55e0a312bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8686594202898551\n",
            "Precision: 0.8719575828205968\n",
            "Recall: 0.8703652218189936\n",
            "F1-Score: 0.8697453969480732\n"
          ]
        }
      ],
      "source": [
        "y_pred_svm = svm_grid.predict(X_test)\n",
        "print(f\"Accuracy: {my_accuracy_score(y_test, y_pred_svm)}\")\n",
        "print(f\"Precision: {my_precision_score(y_test, y_pred_svm)}\")\n",
        "print(f\"Recall: {my_recall_score(y_test, y_pred_svm)}\")\n",
        "print(f\"F1-Score: {my_f1_score(y_test, y_pred_svm)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJHk4fG17Lx",
        "outputId": "6c157425-eb7f-44d8-f265-4adb73b431ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Подбор параметров для Logistic Regression...\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Лучшие параметры Logistic Regression: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Лучшая точность Logistic Regression (кросс-валидация): 0.9499425618715658\n"
          ]
        }
      ],
      "source": [
        "lr_param_grid = {\n",
        "    'C': [0.1],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [1000]\n",
        "}\n",
        "\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "\n",
        "lr_grid = GridSearchCV(\n",
        "    lr_model,\n",
        "    lr_param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Подбор параметров для Logistic Regression...\")\n",
        "lr_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры Logistic Regression:\", lr_grid.best_params_)\n",
        "print(\"Лучшая точность Logistic Regression (кросс-валидация):\", lr_grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTIUE6352FgW",
        "outputId": "2a0a3d31-da5d-4c01-d380-37c83463acd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8831521739130435\n",
            "Precision: 0.8914592760457539\n",
            "Recall: 0.883872409047482\n",
            "F1-Score: 0.8846037292757245\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model = LogisticRegression(random_state=42,C = 0.1, max_iter = 1000, penalty = 'l2', solver = 'saga')\n",
        "lr_model.fit(X_train,y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "print(f\"Accuracy: {my_accuracy_score(y_test, y_pred_lr)}\")\n",
        "print(f\"Precision: {my_precision_score(y_test, y_pred_lr)}\")\n",
        "print(f\"Recall: {my_recall_score(y_test, y_pred_lr)}\")\n",
        "print(f\"F1-Score: {my_f1_score(y_test, y_pred_lr)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
